{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering simulated sequences using TMRCA\n",
    "\n",
    "Name: CQS21 \n",
    "FYP 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing packages to my python environment\n",
    "# NOTE: my pip is v22.0.4 but I cant seemt to update to the newest 24.0\n",
    "\n",
    "#!pip install zarr\n",
    "#!pip install scipy\n",
    "#!pip install scikit-allel\n",
    "#!pip install matplotlib\n",
    "#!pip install tqdm\n",
    "#!pip install dask\n",
    "#!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'allel'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mzarr\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mallel\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhierarchy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msch\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'allel'"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import zarr\n",
    "import allel\n",
    "import scipy.cluster.hierarchy as sch\n",
    "import scipy.spatial\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "from tqdm import tqdm\n",
    "import dask\n",
    "from dask import compute, delayed\n",
    "from itertools import combinations\n",
    "import time\n",
    "import seaborn as sns\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1. Generate burn in simulations establishing nucleotide diversity across a range of parameters (DONE BY PREVIOUS STUDENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see burn in simulations folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2. Conduct 27 variations of partial soft sweep simulations and output vcf files using the HPC facility. Complete x number of repeats.\n",
    "\n",
    "Size of population, N: 100, 1000, 10000\n",
    "\n",
    "Mutation rate, Œº : (0.1/4N), (1/4N), (5/4N)\n",
    "\n",
    "Recombination rate, r : (0.1/4N), (1/4N), (5/4N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3. Read in VCF Files from soft sweep simulations, extract haplotypes using scikit_allel\n",
    "\n",
    "Working with 27 simulation variants and repeats of each variant (100?)\n",
    "\n",
    "but why only look at haplotypes of first 200 individuals? and why calculate sample frequency over specifically 400 haplotypes? is it linked to the 200 individuals = 400 genomes?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = sys.argv[1]\n",
    "#Like Hamming distance code, this was also taken from Anushka Thawani. Adaptations were made to this on the \n",
    "#high-performance computer using shell script, but this could not be represented.\n",
    "def convert(file, genome):\n",
    "    '''\n",
    "    This function extracts haplotypes sequences from a vcf file \n",
    "    Adapted from: http://alimanfoo.github.io/2018/04/09/selecting-variants.html \n",
    "    \n",
    "    Arguments:\n",
    "        file: name of vcf file (from SLiM soft sweep simulation)\n",
    "        genome: length of genome used in SLiM simulation \n",
    "        \n",
    "    Returns:\n",
    "        ht: haplotype sequences for 200 individuals\n",
    "        samp_freq: frequency of sweep mutation in sample\n",
    "        cols: used to color dendrogram\n",
    "\n",
    "    '''\n",
    "    \n",
    "    v = file + '.vcf'\n",
    "    z = file + '.zarr'\n",
    "    slim_sim_data = allel.read_vcf(v, fields='*')\n",
    "    allel.vcf_to_zarr(v, z, fields='*', overwrite=True)\n",
    "    data = zarr.open_group(z, mode='r')\n",
    "    \n",
    " \n",
    "    pos = allel.SortedIndex(data['variants/POS']) # Stores the ID and genomic position of each variant\n",
    "    \n",
    "    # Extract genotypes for the first 200 individuals and convert to haplotypes\n",
    "    gt = data['calldata/GT'][:,0:200] \n",
    "    ht = allel.GenotypeArray(gt).to_haplotypes()\n",
    "    \n",
    "    mutation = int((genome+1)/2) + 1  # position of sweep mutation\n",
    "    \n",
    "    \n",
    "    # Output the frequency of the sweep mutation in the sample\n",
    "    contains_sweep = pos.locate_range(mutation,mutation)\n",
    "    sweep = ht[contains_sweep]\n",
    "    sweep = np.sum(sweep, axis =0)\n",
    "    \n",
    "    samp_freq = np.sum(sweep)/400  # 400 haplotypes\n",
    "    \n",
    "    \n",
    "    # This dictionary is used later to color the dendrogram branches according to whether or not the \n",
    "    # corresponding sequence contains the sweep mutation\n",
    "    cols = {}\n",
    "    for i in range(400):\n",
    "        if sweep[i]:\n",
    "            cols[i] = 'r'  \n",
    "        else:\n",
    "            cols[i] = \"#808080\"\n",
    "    \n",
    "    return ht, pos, samp_freq, cols, sweep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4. Calculate Hij (S or homozygosity) for all pairs of haplotypes\n",
    "make a function \n",
    "homozygosity = (no. of SNPs/ length of window, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_homozygosity (length, genome, ht, sweeploc, pos):\n",
    "    '''\n",
    "    Arguments:\n",
    "    length: length of sliding window\n",
    "    genome : length of genome \n",
    "    ht : vector?  of haplotype sequences from previous function\n",
    "    pos: position of variants from previosu function\n",
    "    sweeploc: position of sweep mutation in genome\n",
    "\n",
    "    \n",
    "    Returns:\n",
    "    homozygosities: homozygosity of all haplotypes in ht in a array(?)\n",
    "    '''\n",
    "    # Make empty vectors\n",
    "    homozygosities = []\n",
    "    mismatch = []\n",
    "    for x in range(0,genome):\n",
    "        start  = x\n",
    "        end = x + length\n",
    "        # locate the position of region around a variant Nt\n",
    "        region = pos.locate_range(start,end) \n",
    "        haplotype_region = ht [region]\n",
    "\n",
    "        #use allel.pairwise distance\n",
    "        pairwise_dist = allel.pairwise_distance(haplotype_region, metric = 'hamming' , chunked=True, blen=None)\n",
    "        homozygosities = pairwise_dist/length\n",
    "\n",
    "    return homozygosities\n",
    "\n",
    "\n",
    "\n",
    "##streamlining: previosu students code say to add a if condition (region =/= prev region to speed up code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5. Calculate Lij from Hij by finding width at half maximum homozygosity\n",
    "where Lij is the shared haplotype length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6. Calculate Tij (Time to common ancestor) from Lij and Kij (which is no. of SNPs) on each shared length (haplotype)\n",
    "\n",
    "ùúè_ùëñùëó=(ùëò_ùëñùëó+1)/(2‚Ñì_ùëñùëó (ùëü+ùúá))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
