{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script for clustering simulated sequences using the TMRCA metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'zarr'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-641c74423133>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mzarr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mallel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhierarchy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'zarr'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import zarr\n",
    "import allel\n",
    "import scipy.cluster.hierarchy as sch\n",
    "import scipy.spatial\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "import dask\n",
    "from dask.delayed import delayed\n",
    "from dask.base import compute\n",
    "from itertools import combinations\n",
    "import time\n",
    "import seaborn as sns\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-4e01bacce47c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#Like Hamming distance code, this was also taken from Anushka Thawani. Adaptations were made to this on the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#high-performance computer using shell script, but this could not be represented.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenome\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     '''\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sys' is not defined"
     ]
    }
   ],
   "source": [
    "seed = sys.argv[1]\n",
    "#Like Hamming distance code, this was also taken from Anushka Thawani. Adaptations were made to this on the \n",
    "#high-performance computer using shell script, but this could not be represented.\n",
    "def convert(file, genome):\n",
    "    '''\n",
    "    This function extracts haplotypes sequences from a vcf file \n",
    "    Adapted from: http://alimanfoo.github.io/2018/04/09/selecting-variants.html\n",
    "    \n",
    "    Arguments:\n",
    "        file: name of vcf file (from SLiM soft sweep simulation)\n",
    "        genome: length of genome used in SLiM simulation \n",
    "        \n",
    "    Returns:\n",
    "        ht: haplotype sequences for 200 individuals\n",
    "        samp_freq: frequency of sweep mutation in sample\n",
    "        cols: used to color dendrogram\n",
    "\n",
    "    '''\n",
    "    \n",
    "    v = file + '.vcf'\n",
    "    z = file + '.zarr'\n",
    "    slim_sim_data = allel.read_vcf(v, fields='*')\n",
    "    allel.vcf_to_zarr(v, z, fields='*', overwrite=True)\n",
    "    data = zarr.open_group(z, mode='r')\n",
    "    \n",
    " \n",
    "    pos = allel.SortedIndex(data['variants/POS']) # Stores a sorted index of the ID and genomic position of each variant\n",
    "    \n",
    "    # Extract genotypes for the first 200 individuals and convert to haplotypes\n",
    "    gt = data['calldata/GT'][:,0:200] \n",
    "    ht = allel.GenotypeArray(gt).to_haplotypes()\n",
    "    \n",
    "    mutation = int((genome+1)/2) + 1  # position of sweep mutation\n",
    "    \n",
    "    \n",
    "    # Output the frequency of the sweep mutation in the sample\n",
    "    contains_sweep = pos.locate_range(mutation,mutation)\n",
    "    sweep = ht[contains_sweep]\n",
    "    sweep = np.sum(sweep, axis =0)\n",
    "    \n",
    "    samp_freq = np.sum(sweep)/400  # 400 haplotypes\n",
    "    \n",
    "    \n",
    "    # This dictionary is used later to color the dendrogram branches according to whether or not the \n",
    "    # corresponding sequence contains the sweep mutation\n",
    "    cols = {}\n",
    "    for i in range(400):\n",
    "        if sweep[i]:\n",
    "            cols[i] = 'r'  \n",
    "        else:\n",
    "            cols[i] = \"#808080\"\n",
    "    \n",
    "    return ht, pos, samp_freq, cols, sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_distance(L, mutation, genome, haplotypes, pos, gts): \n",
    "    '''\n",
    "    This function calculates the sliding window homozygosity for all pairs of haplotype sequences\n",
    "    \n",
    "    Arguments:\n",
    "        L: length of sliding window\n",
    "        mutation: position of sweep mutation in genome\n",
    "        genome: length of genomes\n",
    "        haplotypes: haplotype sequences\n",
    "        pos: positions of variants\n",
    "        gts: number of haplotype pairs\n",
    "        \n",
    "    Returns:\n",
    "        hom: sliding homozygosity for all pairs of sequences\n",
    "    '''\n",
    "    \n",
    "    # Initialise empty vector \n",
    "    hom = np.empty(shape=(genome,gts),dtype=np.float32)  \n",
    "\n",
    "    reg =  slice(-100, -100, None)\n",
    "    \n",
    "    \n",
    "    for x in range(0,genome):\n",
    "        start  = x\n",
    "        end = x + L\n",
    "        try:    \n",
    "            region = pos.locate_range(start,end)  \n",
    "            # Check if the current window (region) is different from the previous window (reg) - makes code faster\n",
    "            if region != reg:\n",
    "                htx = haplotypes[region]\n",
    "                d = allel.pairwise_distance(htx, metric=\"hamming\")\n",
    "                hom[x,:] = 1-d  # 1-hamming distance = homozygosity\n",
    "                reg = region\n",
    "    \n",
    "            else:\n",
    "                hom[x,:] = 1-d\n",
    "\n",
    "        except KeyError:\n",
    "            pass\n",
    "    \n",
    "    return hom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_troughs(smooth, mutation_pos):\n",
    "    '''\n",
    "    This function calculates the shared haplotype lengths (SHLs) for all pairs of haplotype sequences\n",
    "    \n",
    "    Arguments:\n",
    "        smooth: smoothed sliding window homogosity for all pairs of sequences\n",
    "        mutation_pos: position of sweep mutation in genome\n",
    "        \n",
    "    Returns:\n",
    "        lower: position of breakpoint left of the sweep site\n",
    "        upper: position of breakpoint right of the sweep site\n",
    "        SHL: shared haplotype length\n",
    "    '''\n",
    "    \n",
    "    troughs = scipy.signal.find_peaks(-smooth)\n",
    "    troughs = troughs[0]     # Indexes of all troughs\n",
    "    troughs = troughs[smooth[troughs] < thresh]   # Extract troughs where homozygosity<0.87\n",
    "    \n",
    "    peaks = scipy.signal.find_peaks(smooth)\n",
    "    peaks = peaks[0] \n",
    "    \n",
    "    bp = np.searchsorted(troughs,mutation_pos)   # Find positions of troughs flanking sweep site\n",
    "    lower = troughs[bp - 1]\n",
    "    upper = troughs[bp]\n",
    "    \n",
    "    # Find the average peak position around the sweep site\n",
    "    highest = peaks[(peaks >= lower) & (peaks <= upper)]\n",
    "    if highest.size != 0:\n",
    "        highest = np.mean(highest)\n",
    "    else: \n",
    "        highest = (lower+upper)/2\n",
    "    \n",
    "    \n",
    "    lower = (lower+highest)/2\n",
    "    upper = (upper+highest)/2\n",
    "\n",
    "    SHL = upper - lower\n",
    "    \n",
    "    return int(lower), int(upper), SHL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_breakpoint(haplotype_pair):\n",
    "    '''\n",
    "    For a pair of sequences, this function smoothes the sliding homozygosity and returns the SHL\n",
    "    Arguments:\n",
    "        haplotype_pair: a pair of haplotype sequences\n",
    "        \n",
    "    Returns:\n",
    "        lower: position of breakpoint left of the sweep site\n",
    "        upper: position of breakpoint right of the sweep site\n",
    "        SHL: shared haplotype length\n",
    "    '''\n",
    "    \n",
    "    mutation_pos = mutation \n",
    "    smooth = gaussian_filter1d(haplotype_pair, points_g)\n",
    "    try:\n",
    "        lower, upper, SHL = find_troughs(smooth, mutation_pos)\n",
    "    except IndexError:\n",
    "        lower = -1.3\n",
    "        upper = -1.3\n",
    "        SHL = -1.3\n",
    "        \n",
    "    return lower, upper, SHL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_snp(n,gts,ht,results_computed_1,pos):\n",
    "    '''\n",
    "    This function finds the number of SNPs over the shared haplotype length for all pairs of haplotype sequences\n",
    "    \n",
    "    Arguments:\n",
    "        n: number of haplotype sequences\n",
    "        gts: number of haplotype pairs\n",
    "        ht: haplotype sequnces\n",
    "        results_computed_1: output from find_breakpoint function\n",
    "        \n",
    "    Returns:\n",
    "        diffs: number of SNPs for all pairs of haplotype sequences\n",
    "        \n",
    "    '''\n",
    "    pairwise = []\n",
    "    for combo in combinations(list(range(0,n)), 2): \n",
    "        pairwise.append(combo)\n",
    "\n",
    "    diffs = np.empty(shape=(gts),dtype=np.float32)\n",
    "    for i in range(gts):\n",
    "        pair = ht[:,pairwise[i]]\n",
    "        try:\n",
    "            start = results_computed_1[i,1]\n",
    "            stop = results_computed_1[i,2]\n",
    "\n",
    "            window_pos = pos.locate_range(start, stop)\n",
    "            window = pair[window_pos]\n",
    "\n",
    "            d = allel.pairwise_distance(window, metric = \"hamming\")\n",
    "\n",
    "            diffs[i]=d \n",
    "\n",
    "        except KeyError:\n",
    "            diffs[i]=-1.3 \n",
    "    \n",
    "    return diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(file,genome,pop,window,threshold,points,r=1,u=1): \n",
    "    '''\n",
    "    This function clusters the sequences stored in a .vcf file.\n",
    "    \n",
    "    Arguments:\n",
    "        file: name of vcf file\n",
    "        genome: length of genome (in SLiM simulation)\n",
    "        pop: effective population size (in SLiM simulation)\n",
    "        window: length of sliding window\n",
    "        threshold: threshold above which troughs are ignored\n",
    "        points: number of points to use for 1D-gaussian filter (see scipy documentation)\n",
    "        r: recombination rate\n",
    "        u: mutation rate \n",
    "    '''\n",
    "    \n",
    "    print(file)\n",
    "\n",
    "    global mutation\n",
    "    mutation = int((genome+1)/2) \n",
    "    global thresh\n",
    "    thresh=threshold\n",
    "    global points_g\n",
    "    points_g = points\n",
    "    \n",
    "    # Extract haplotype sequences from .vcf file\n",
    "    ht, pos, samp_freq, cols, sweep = convert(file, genome)\n",
    "\n",
    "    \n",
    "    # Calculate sliding homozygosity for all pairs of haplotype sequences\n",
    "    L=window\n",
    "    n = 400 #number of haplotypes \n",
    "    gts = int((n*(n-1))/2)\n",
    "    hom = sliding_distance(L, mutation, genome, ht, pos, gts)\n",
    "\n",
    "    \n",
    "    # Find SHL for all pairs of haplotype sequences \n",
    "    hom_dask = dask.array.from_array(hom, chunks=(genome,1)) \n",
    "    hom = []\n",
    "    results = dask.array.apply_along_axis(find_breakpoint,0,hom_dask) \n",
    "    results_computed = results.compute()\n",
    "\n",
    "    # Manipulating the dataframe to make it easier to process\n",
    "    results_computed = np.transpose(results_computed)\n",
    "    index = np.asarray(range(0,gts))\n",
    "    index = np.expand_dims(index, axis=0)\n",
    "    results_computed_1 = np.concatenate((index.T, results_computed), axis=1)\n",
    "    \n",
    "    \n",
    "    # Calculate the TMRCA from the SHLs and number of SNPs\n",
    "    r = r/(2*pop) #erm wtf?\n",
    "    u = u/(100*pop) #erm wtf?\n",
    "    shls = results_computed_1[:,3]   # SHLs for all pairs of haplotype sequences \n",
    "    shls[shls<=0] = genome\n",
    "    diffs = find_snp(n,gts,ht,results_computed_1,pos)  # SNPs for all pairs of haplotype sequences \n",
    "    snp = (1+(diffs*shls))/(2*shls*(r + u)) # TMRCA metric for all pairs of haplotype sequences \n",
    "\n",
    "    \n",
    "    # Remove negative and non-integer TMRCA values\n",
    "    impute = np.nanmean(snp)\n",
    "    x = np.isfinite(snp)\n",
    "    for i in np.where(x == 0)[0]:\n",
    "        snp[i] = impute\n",
    "    snp[snp<=0] = impute  \n",
    "    \n",
    "    \n",
    "    # Clustering \n",
    "    Z = sch.linkage(snp, method = 'complete')\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Plot dendrogram without colouring branches\n",
    "    matplotlib.rcParams.update({'font.size': 24})\n",
    "    fig = plt.figure(figsize=(30, 12))\n",
    "    gs = matplotlib.gridspec.GridSpec(2, 1, hspace=0.1, wspace=1, height_ratios=(1,1))\n",
    "\n",
    "    ax_dend = fig.add_subplot(gs[0, 0])\n",
    "    sns.despine(ax=ax_dend, offset=5, bottom=True, top=True)\n",
    "    dd = sch.dendrogram(Z,color_threshold=0,above_threshold_color='#808080',ax=ax_dend)\n",
    "\n",
    "    ls = []\n",
    "    for leaf, leaf_color in zip(plt.gca().get_xticklabels(), dd[\"leaves_color_list\"]):\n",
    "        leaf.set_color(cols[int(leaf.get_text())])\n",
    "        ls.append(int(leaf.get_text()))\n",
    "\n",
    "    ax_dend.set_ylabel('Haplotype age/generations',fontsize=24)\n",
    "    ax_dend.set_title('Haplotype clusters',fontsize=24)\n",
    "    \n",
    "    \n",
    "    # Plot dendrogram and colour branches\n",
    "    \n",
    "    ax_dend_2 = fig.add_subplot(gs[1, 0])\n",
    "    \n",
    "    dflt_col = \"#808080\"\n",
    "    \n",
    "    link_cols = {}\n",
    "    for i, i12 in enumerate(Z[:,:2].astype(int)):\n",
    "        c1, c2 = (link_cols[x] if x > len(Z) else cols[x] for x in i12)\n",
    "        link_cols[i+1+len(Z)] = c1 if c1 == c2 else dflt_col\n",
    "\n",
    "    sns.despine(ax=ax_dend_2, offset=5, bottom=True, top=True)\n",
    "    dd = sch.dendrogram(Z,color_threshold=None,link_color_func=lambda x: link_cols[x],ax=ax_dend_2)\n",
    "\n",
    "    ls = []\n",
    "    for leaf, leaf_color in zip(plt.gca().get_xticklabels(), dd[\"leaves_color_list\"]):\n",
    "        leaf.set_color(cols[int(leaf.get_text())])\n",
    "        ls.append(int(leaf.get_text()))\n",
    "\n",
    "    ax_dend_2.set_ylabel('Haplotype age/generations',fontsize=24)\n",
    "    \n",
    "    \n",
    "    # Save dendrogram\n",
    "    output = 'accurate_' + file + '.pdf'\n",
    "    plt.savefig(output)  \n",
    "        \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis(file='001_C',genome=39999,pop=1000,r=0.1,window=1000,threshold=0.87,points=280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis(['001_A',39999,1000],r=0.1,window=1000,threshold=0.87,points=280)\n",
    "# analysis(['001_B',39999,1000],r=0.1,window=1000,threshold=0.87,points=280)\n",
    "# analysis(['001_C',39999,1000],r=0.1,window=1000,threshold=0.87,points=280)\n",
    "# analysis(['001_D',39999,1000],r=0.1,window=1000,threshold=0.87,points=280)\n",
    "# analysis(['001_E',39999,1000],r=0.1,window=1000,threshold=0.87,points=280)\n",
    "\n",
    "# analysis(['002_A',19999,1000],r=1,window=600,threshold=0.87,points=250)\n",
    "# analysis(['002_B',19999,1000],r=1,window=600,threshold=0.87,points=250)\n",
    "# analysis(['002_C',19999,1000],r=1,window=600,threshold=0.87,points=250)\n",
    "# analysis(['002_D',19999,1000],r=1,window=600,threshold=0.87,points=250)\n",
    "# analysis(['002_E',19999,1000],r=1,window=600,threshold=0.87,points=250)\n",
    "\n",
    "# analysis(['003_A',9999,1000],r=10,window=500,threshold=0.99,points=210)\n",
    "# analysis(['003_B',9999,1000],r=10,window=500,threshold=0.99,points=210)\n",
    "# analysis(['003_C',9999,1000],r=10,window=500,threshold=0.99,points=210)\n",
    "# analysis(['003_D',9999,1000],r=10,window=500,threshold=0.99,points=210)\n",
    "# analysis(['003_E',9999,1000],r=10,window=500,threshold=0.99,points=210)\n",
    "\n",
    "# analysis(['004_A',99999,1000],r=0.01,window=1000,threshold=0.87,points=280)\n",
    "# analysis(['004_B',99999,1000],r=0.01,window=1000,threshold=0.87,points=280)\n",
    "# analysis(['004_C',99999,1000],r=0.01,window=1000,threshold=0.87,points=280)\n",
    "# analysis(['004_D',99999,1000],r=0.01,window=1000,threshold=0.87,points=280)\n",
    "# analysis(['004_E',99999,1000],r=0.01,window=1000,threshold=0.87,points=280)\n",
    "\n",
    "# analysis(['005_A',99999,1000],r=0.01,window=1000,threshold=0.87,points=280)\n",
    "# analysis(['005_B',99999,1000],r=0.01,window=1000,threshold=0.87,points=280)\n",
    "# analysis(['005_C',99999,1000],r=0.01,window=1000,threshold=0.87,points=280)\n",
    "# analysis(['005_D',99999,1000],r=0.01,window=1000,threshold=0.87,points=280)\n",
    "# analysis(['005_E',99999,1000],r=0.01,window=1000,threshold=0.87,points=280)\n",
    "\n",
    "# analysis(['006_A',99999,1000],r=0.01,window=1000,threshold=0.87,points=280)\n",
    "# analysis(['006_B',99999,1000],r=0.01,window=1000,threshold=0.87,points=280)\n",
    "# analysis(['006_C',99999,1000],r=0.01,window=1000,threshold=0.87,points=280)\n",
    "# analysis(['006_D',99999,1000],r=0.01,window=1000,threshold=0.87,points=280)\n",
    "# analysis(['006_E',99999,1000],r=0.01,window=1000,threshold=0.87,points=280)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
